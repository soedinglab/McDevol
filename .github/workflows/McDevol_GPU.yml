name: McDevol_GPU
on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  gpu-job:
    runs-on: [self-hosted, gpu]
    
    steps:
    - uses: actions/checkout@v4

    - name: Set up Conda environment
      uses: conda-incubator/setup-miniconda@v3
      with:
        activate-environment: mcdevol_env
        environment-file: environment.yml
        auto-activate-base: false

    - name: Install CUDA and cuDNN
      run: |
        conda install -c conda-forge cudatoolkit=11.0 cudnn=8.9

    - name: Verify GPU availabilityyour_gpu_script.py
      run: |
        python -c "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"
        python -c "import torch; print(torch.cuda.is_available())"

    - name: Run your GPU-dependent script
      run: |
        # Replace this with your actual script that uses GPU
        python mcdevol/mcdevol.py -h
